{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 750M (CNMeM is enabled with initial size: 10.0% of memory, cuDNN 5004)\n",
      "//anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import six.moves.cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        self.W = theano.shared(\n",
    "            value = numpy.zeros((n_in, n_out), dtype = theano.config.floatX),\n",
    "            name = \"W\",\n",
    "            borrow = True\n",
    "        )\n",
    "        self.b = theano.shared(\n",
    "            value = numpy.zeros((n_out, ), dtype = theano.config.floatX),\n",
    "            name = \"b\",\n",
    "            borrow = True\n",
    "        )\n",
    "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)\n",
    "        self.y_pred = T.argmax(self.p_y_given_x, axis = 1)\n",
    "        self.params = [self.W, self.b]\n",
    "        self.input = input\n",
    "    \n",
    "    def negloglik(self, y, lamb):\n",
    "        return (-T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y]) +\\\n",
    "                lamb * T.sum(abs(self.W)))\n",
    "    \n",
    "    def errors(self, y):\n",
    "        if y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError(\n",
    "                'y should have the same shape as self.y_pred',\n",
    "                ('y', y.type, 'y_pred', self.y_pred.type)\n",
    "            )\n",
    "        if y.dtype.startswith('int'):\n",
    "            return T.mean(T.neq(self.y_pred, y))\n",
    "        else:\n",
    "            raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('/Users/tnybny/Documents/Kaggle/Digit recognizer/Data/train', 'r') as f:\n",
    "        D = pickle.load(f)[1:, ]\n",
    "        indices = numpy.random.permutation(D.shape[0])\n",
    "        tr_idx, va_idx = indices[:28000], indices[28001:]\n",
    "        train_set = (D[tr_idx, 1:], D[tr_idx, 0])\n",
    "        valid_set = (D[va_idx, 1:], D[va_idx, 0])\n",
    "    with open('/Users/tnybny/Documents/Kaggle/Digit recognizer/Data/test', 'r') as f:\n",
    "        Dtest = pickle.load(f)[1:, ]\n",
    "        test_set = (Dtest, Dtest[:, 0])\n",
    "\n",
    "    def shared_dataset(data_xy, borrow = True):\n",
    "        data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(numpy.asarray(data_x,\n",
    "                                              dtype = theano.config.floatX),\n",
    "                                borrow = borrow)\n",
    "        shared_y = theano.shared(numpy.asarray(data_y,\n",
    "                                              dtype = theano.config.floatX),\n",
    "                                borrow = borrow)\n",
    "        return shared_x, T.cast(shared_y, 'int32')\n",
    "    \n",
    "    Xtrain, ytrain = shared_dataset(train_set)\n",
    "    Xval, yval = shared_dataset(valid_set)\n",
    "    Xtest, ytest = shared_dataset(test_set)\n",
    "    rval = [(Xtrain, ytrain), (Xval, yval), (Xtest, ytest)]\n",
    "    return rval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_optimization_mnist(D, alpha = 0.001, lamb = 0.1, n_epochs = 100, batch_size = 100):\n",
    "    Xtrain, ytrain = D[0]\n",
    "    Xval, yval = D[1]\n",
    "    Xtest, ytest = D[2]\n",
    "\n",
    "    n_train_batches = Xtrain.get_value(borrow = True).shape[0] // batch_size\n",
    "    n_valid_batches = Xval.get_value(borrow = True).shape[0] // batch_size\n",
    "    \n",
    "    index = T.lscalar() # mini-batch index\n",
    "    x = T.matrix('x') # symbols for inputs and outputs\n",
    "    y = T.ivector('y')\n",
    "    \n",
    "    classifier = LogisticRegression(input = x, n_in = 28 * 28, n_out = 10)\n",
    "    cost = classifier.negloglik(y, lamb)\n",
    "    \n",
    "    test_model = theano.function(\n",
    "        inputs = [index],\n",
    "        outputs = classifier.errors(y),\n",
    "        givens = {\n",
    "            x: Xtest[index * batch_size: (index + 1) * batch_size],\n",
    "            y: ytest[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    valid_model = theano.function(\n",
    "        inputs = [index],\n",
    "        outputs = classifier.errors(y),\n",
    "        givens = {\n",
    "            x: Xval[index * batch_size: (index + 1) * batch_size],\n",
    "            y: yval[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    g_W = T.grad(cost = cost, wrt = classifier.W)\n",
    "    g_b = T.grad(cost = cost, wrt = classifier.b)\n",
    "    \n",
    "    updates = [(classifier.W, classifier.W - alpha * g_W),\n",
    "               (classifier.b, classifier.b - alpha * g_b)]\n",
    "    \n",
    "    train_model = theano.function(\n",
    "        inputs = [index],\n",
    "        outputs = classifier.errors(y),\n",
    "        updates = updates,\n",
    "        givens = {\n",
    "            x: Xtrain[index * batch_size: (index + 1) * batch_size],\n",
    "            y: ytrain[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    improvement_threshold = 0.95\n",
    "    validation_frequency = n_train_batches\n",
    "    best_valid_loss = numpy.inf\n",
    "    best_minibatch_loss = numpy.inf\n",
    "    test_score = 0.\n",
    "    epoch = 0\n",
    "    costs = []\n",
    "    valid_costs = []\n",
    "    train_costs = []\n",
    "    while (epoch < n_epochs):\n",
    "        epoch = epoch + 1\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "                    alpha = alpha / 2\n",
    "        \n",
    "        for minibatch_index in range(n_train_batches):\n",
    "            minibatch_avg_cost = train_model(minibatch_index)\n",
    "            train_costs.append(minibatch_avg_cost)\n",
    "            \n",
    "            iter = (epoch - 1) * n_train_batches + minibatch_index # count iterations\n",
    "            if (iter + 1) % validation_frequency == 0:\n",
    "                    \n",
    "                valid_losses = [valid_model(i) for i in range(n_valid_batches)]\n",
    "                this_valid_loss = numpy.mean(valid_losses)\n",
    "                valid_costs.append(this_valid_loss)\n",
    "                costs.append(numpy.mean(train_costs))\n",
    "                train_costs = []\n",
    "                \n",
    "                print(\n",
    "                    'epoch %i, minibatch %i/%i, validation error %f %%' %\n",
    "                    (\n",
    "                        epoch,\n",
    "                        minibatch_index + 1,\n",
    "                        n_train_batches,\n",
    "                        this_valid_loss * 100.\n",
    "                    )\n",
    "                )\n",
    "                    \n",
    "                if this_valid_loss < best_valid_loss:\n",
    "                    best_valid_loss = this_valid_loss\n",
    "\n",
    "                    with open('LogReg/best_model.pkl', 'wb') as f:\n",
    "                        pickle.dump(classifier, f)\n",
    "    print(\n",
    "        (\n",
    "            'Optimization complete with best validation score of %f %%,'\n",
    "            'with test performance %f %%'\n",
    "        )\n",
    "        % (best_valid_loss * 100., test_score * 100.)\n",
    "    )\n",
    "    print('The code run for %d epochs') % (epoch)\n",
    "    return costs, valid_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "    classifier = pickle.load(open('LogReg/best_model.pkl'))\n",
    "    \n",
    "    predict_model = theano.function(\n",
    "        inputs = [classifier.input],\n",
    "        outputs = classifier.y_pred)\n",
    "    \n",
    "    D = load_data()\n",
    "    Xtest, ytest = D[2]\n",
    "    Xtest = Xtest.get_value()\n",
    "\n",
    "    predicted_values = predict_model(Xtest)\n",
    "    numpy.savetxt('LogReg/submission.csv',\n",
    "                  numpy.c_[range(1, Xtest.shape[0] + 1), predicted_values],\n",
    "                  delimiter = ',', header = 'ImageId,Label', comments = '', fmt = '%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = load_data()\n",
    "costs = []\n",
    "valid_costs = []\n",
    "alphas = numpy.random.uniform(0.0001, 0.1, 5).tolist() # random search is better than a grid search\n",
    "lambdas = numpy.random.uniform(0.01, 10, 5).tolist() # over hyperparameter space\n",
    "cost, valid_cost = sgd_optimization_mnist(D, 0.000002, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(valid_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
